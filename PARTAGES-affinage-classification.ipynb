{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVrj8urZVCWa"
   },
   "source": [
    "# üè• Affinage (*fine-tuning*) de mod√®les encodeurs PARTAGES (BERT-like) pour la classification de textes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmqlwwZw31V-"
   },
   "source": [
    "### Installation des libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVC4SALTcRzM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parfois il est plus simple d'installer torch via conda (ou d'utiliser le\n",
    "# paquet pytorch). S'il y a des erreurs avec numpy installez 'numpy<2'.\n",
    "\n",
    "# On utilise `datasets<4` car la version 4 de tokenizer ne permet plus de charger\n",
    "# des jeux de donn√©es √† l'aide de scripts de chargement. Certains jeux de\n",
    "# donn√©es utilisent toujours des scripts de chargements (notamment DrBenchmark).\n",
    "\n",
    "%pip install 'transformers[torch]' 'datasets<4' tensorboardX torch\n",
    "%pip install scikit-learn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dC_XWPjP8Ikv"
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "###########    A Modifier    #########\n",
    "######################################\n",
    "\n",
    "# Si le jeu de donn√©e, mod√®le ou tokeniseur n'est pas public sur huggingface il\n",
    "# faut utiliser un jeton de connexion √† cr√©er ici : https://huggingface.co/settings/tokens\n",
    "\n",
    "# Pour l'instant les mod√®les PARTAGES sont priv√©s et accessibles avec le jeton\n",
    "#  communiqu√© avec ce fichier\n",
    "HF_TOKEN = \"\"\n",
    "\n",
    "# Ici on utilise un des mod√®les du projet PARTAGES\n",
    "# A modifier pour utiliser un autre mod√®le comme base d'affinage\n",
    "BASE_MODEL_NAME = \"PARTAGES-dev/PARTAGES-encoder-v1\"\n",
    "\n",
    "######################################\n",
    "\n",
    "# Petit hack pour √©viter un avertissement sp√©cifique √† Google Colab sur le\n",
    "# chargement du jeton huggingface\n",
    "try:\n",
    "  from huggingface_hub.utils import _auth\n",
    "  _auth._get_token_from_google_colab = lambda: None\n",
    "except ImportError:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APx2gM0C5OsO"
   },
   "source": [
    "### Chargement du tokeniseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwWso1vocYuG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME, token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxJpOo-cdW_a"
   },
   "source": [
    "### Chargement et pr√©paration des donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D40ui_UX8R2G"
   },
   "source": [
    "Chargement des donn√©es, la colonne 'specialities_one_hot' est une liste qui repr√©sente les √©tiquettes a associer √† ce document.\n",
    "Par exemple si l'ensemble des √©tiquettes possibles est : `immunitaire`, `blessures`, `chimiques` et `virales`. Chaque document sera repr√©sent√© par une liste de 4 √©l√©ments correspondant aux 4 √©tiquettes. Ainsi un document devant √™tre class√© comme `immunitaire` et `virales` aura le vecteur suivant: `[1, 0, 0, 1]`.\n",
    "\n",
    "```python\n",
    "[{'id': str, 'text': list(str), 'specialities_one_hot': list(int)}, ...]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkCeSgx23fq_"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(e, texts_column, labels_column, max_length=None):\n",
    "    if max_length is None:\n",
    "        max_length = tokenizer.model_max_length\n",
    "    res = tokenizer(e[texts_column], truncation=True, max_length=max_length, padding='do_not_pad')\n",
    "    # Pas de padding lors du pr√©traitement, c'est le DataCollator qui s'en chargera plus tard.\n",
    "    res[\"label\"] = e[labels_column]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def one_hot_encoding(labels, num_labels):\n",
    "    vector = torch.zeros(num_labels)\n",
    "    vector[labels] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "###########    ZONE A Modifier POUR UTILISER    #########\n",
    "###########         VOS PROPRES DONNEES         #########\n",
    "##          ATTENTION AUX DONNEES PRIVEES NE PAS       ##\n",
    "##              EXECUTER SUR LE CLOUD                  ##\n",
    "#########################################################\n",
    "# En sortie de ces cellule:\n",
    "#  - label_list : liste des diff√©rentes √©tiquettes\n",
    "#  - train_dataset : un Dataset tokenis√© avec une colonne \"label\"\n",
    "#  - eval_dataset : un Dataset tokenis√© avec une colonne \"label\"\n",
    "#  - PROBLEM_TYPE : qui sera utilis√© pour charger le mod√®le \n",
    "\n",
    "# L'exemple est avec le corpus DEFT2021 que l'on peut obtenir via la collection\n",
    "#  de DrBenchmark (cf github.com/DrBenchmark/DrBenchmark)\n",
    "# https://talnarchives.atala.org/ateliers/2021/DEFT/77.pdf\n",
    "# Chaque cas clinique est associ√© √† des etiquettes d√©crivant le profil cliniques\n",
    "#  du patient. Apr√®s extraction, le corps du texte est tokenis√© via la fonction\n",
    "#  preprocess_function.\n",
    "\n",
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset('DrBenchmark/DEFT2021', 'cls', trust_remote_code=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = \"specialities\"\n",
    "\n",
    "print(\"Exemple d'√©tiquettes:\")\n",
    "for doc in dataset['train'].select(range(3))[label_column]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si plusieurs etiquettes par document\n",
    "PROBLEM_TYPE = \"multi_label_classification\"\n",
    "\n",
    "label_list = dataset[\"train\"].features[label_column].feature.names\n",
    "\n",
    "# Si Attribute Error: les features du dataset ne sont pas d√©finies, on r√©cup√®re\n",
    "#  toutes les √©tiquettes de tout les documents\n",
    "#label_list = list({label for split in dataset for doc in dataset[split][label_column] for label in doc})\n",
    "\n",
    "id2label = {i: l for i, l in enumerate(label_list)}\n",
    "label2id = {l: i for i, l in id2label.items()}\n",
    "print(\"Dictionnaire √©tiquette->identifiant:\")\n",
    "print(id2label)\n",
    "\n",
    "# On copie les labels dans la colonne 'label' pour en faciliter la modification\n",
    "dataset = dataset.map(lambda d: {'label': d[label_column]})\n",
    "\n",
    "# Si les etiquettes sont des chaines de caract√®re il faut les transformer en entier\n",
    "# dataset = dataset.map(lambda d: {'label': [label2id[l] for l in d['label']]})\n",
    "# On encode les etiquettes en vecteur\n",
    "dataset = dataset.map(lambda d: {'label': one_hot_encoding(d['label'], len(id2label))})\n",
    "\n",
    "# On s'assure que les labels sont bien des flottants (pour le calcul de la loss)\n",
    "dataset = dataset.cast_column('label', datasets.Sequence(datasets.Value(\"float\")))\n",
    "\n",
    "# Affichage d'un exemple pour v√©rifier que tout est correct\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIWsbLfEciAo"
   },
   "outputs": [],
   "source": [
    "# Si une etiquette par document\n",
    "\"\"\"\n",
    "PROBLEM_TYPE = \"single_label_classification\"\n",
    "\n",
    "label_list = dataset[\"train\"].features[label_column].feature.names\n",
    "\n",
    "# Si Attribute Error: les features du dataset ne sont pas d√©finies, on r√©cup√®re\n",
    "#  toutes les √©tiquettes de tout les documents\n",
    "#label_list = list({label for split in dataset for label in dataset[split][label_column]})\n",
    "\n",
    "id2label = {i: l for i, l in enumerate(label_list)}\n",
    "label2id = {l: i for i, l in id2label.items()}\n",
    "print(id2label)\n",
    "\n",
    "# On copie les labels dans la colonne 'label' pour en faciliter la modification\n",
    "dataset = dataset.map(lambda d: {'label': d[label_column]})\n",
    "\n",
    "# Si les etiquettes sont des chaines de caract√®re il faut les transformer en entier\n",
    "#dataset = dataset.map(lambda d: {'label': label2id[d['label']]})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Tokenize dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m tokenized_dataset = \u001b[43mdataset\u001b[49m.map(\n\u001b[32m      3\u001b[39m     preprocess_function,\n\u001b[32m      4\u001b[39m     fn_kwargs={\n\u001b[32m      5\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtexts_column\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      6\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mlabels_column\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      7\u001b[39m         \u001b[38;5;66;03m# On met un maximum a 8192 pour √©viter les erreurs de m√©moire li√©s au\u001b[39;00m\n\u001b[32m      8\u001b[39m         \u001b[38;5;66;03m#  traitement de long documents mais c'est a modifier selon les besoins\u001b[39;00m\n\u001b[32m      9\u001b[39m         \u001b[38;5;66;03m#  et capacit√©s de calcul. Certains mod√®le n'ayant pas de limite.\u001b[39;00m\n\u001b[32m     10\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmax_length\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mmin\u001b[39m(tokenizer.model_max_length, \u001b[32m8192\u001b[39m),\n\u001b[32m     11\u001b[39m     },\n\u001b[32m     12\u001b[39m     batched=\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size=\u001b[32m100\u001b[39m,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Split dataset into train and validation sets\u001b[39;00m\n\u001b[32m     16\u001b[39m train_dataset = tokenized_dataset[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Tokenize dataset\n",
    "tokenized_dataset = dataset.map(\n",
    "    preprocess_function,\n",
    "    fn_kwargs={\n",
    "        'texts_column': 'text',\n",
    "        'labels_column': 'label',\n",
    "        # On met un maximum a 8192 pour √©viter les erreurs de m√©moire li√©s au\n",
    "        #  traitement de long documents mais c'est a modifier selon les besoins\n",
    "        #  et capacit√©s de calcul. Certains mod√®le n'ayant pas de limite.\n",
    "        'max_length': min(tokenizer.model_max_length, 8192),\n",
    "    },\n",
    "    batched=True, batch_size=100,\n",
    ")\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_dataset = tokenized_dataset[\"train\"]\n",
    "eval_dataset = tokenized_dataset[\"validation\"]\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqAJdaNnbEbJ"
   },
   "outputs": [],
   "source": [
    "# Affichage de quelques statistiques du corpus\n",
    "import random\n",
    "import textwrap\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Affichage d'exemples au hasard\n",
    "to_show = [15, random.randrange(len(train_dataset))]\n",
    "\n",
    "print(f\"Etiquettes : {label_list}\")\n",
    "idx_train_longest = int(np.argmax([len(e) for e in train_dataset['input_ids']]))\n",
    "print(f\"Plus long  doc train : idx {idx_train_longest:4d}, len {len(train_dataset[idx_train_longest]['input_ids']):4d}\")\n",
    "idx_train_shortest = int(np.argmin([len(e) for e in train_dataset['input_ids']]))\n",
    "print(f\"Plus court doc train : idx {idx_train_shortest:4d}, len {len(train_dataset[idx_train_shortest]['input_ids']):4d}\")\n",
    "\n",
    "idx_eval_longest = int(np.argmax([len(e) for e in eval_dataset['input_ids']]))\n",
    "print(f\"Plus long  doc valid : idx {idx_eval_longest:4d}, len {len(eval_dataset[idx_eval_longest]['input_ids']):4d}\")\n",
    "idx_eval_shortest = int(np.argmin([len(e) for e in eval_dataset['input_ids']]))\n",
    "print(f\"Plus court doc valid : idx {idx_eval_shortest:4d}, len {len(eval_dataset[idx_eval_shortest]['input_ids']):4d}\")\n",
    "\n",
    "for i in to_show:\n",
    "    doc = train_dataset[i]\n",
    "    print(f\"------ Document train {i} ------\")\n",
    "    print(f\"Nb. tokens: {len(doc['input_ids'])}\")\n",
    "    tokens = ' '.join(tokenizer.convert_ids_to_tokens(doc['input_ids'])).replace('\\n', '\\\\n')\n",
    "    print(f\"Tokens: {'\\n'.join(textwrap.wrap(tokens, width=120, break_long_words=False, break_on_hyphens=False))}\")\n",
    "    print(f\"Etiquettes: {doc['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAQmfnuZdcMm"
   },
   "source": [
    "### D√©finition des m√©triques a rapporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fx32-9smY2Ev"
   },
   "outputs": [],
   "source": [
    "# Pour calculer le f1-score pendant l'entrainement\n",
    "CLASSIFICATION_THRESHOLD = 0.70\n",
    "# On associe l'√©tiquette au document si sa probabilit√© est sup√©rieure au seuil\n",
    "# (utilis√© dans `compute_metrics`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mfo94xiCexPn"
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "#### A modifier selon les besoins #####\n",
    "#######################################\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "def toLogits(predictions, threshold):\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def multi_label_metrics(predictions, labels, threshold):\n",
    "    y_pred = toLogits(predictions, threshold)\n",
    "    y_true = labels\n",
    "\n",
    "    f1_macro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=.0)\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=.0)\n",
    "    f1_weighted_average = f1_score(y_true=y_true, y_pred=y_pred, average='weighted', zero_division=.0)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average='micro')\n",
    "\n",
    "    metrics = {'f1_macro': f1_macro_average, 'f1_micro': f1_micro_average, 'f1_weighted': f1_weighted_average, 'roc': roc_auc}\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def single_label_metrics(predictions, labels):\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    y_true = labels\n",
    "\n",
    "    average = \"binary\" if predictions.shape[-1] == 2 else \"weighted\"\n",
    "    \n",
    "    f1 = f1_score(y_true=y_true, y_pred=y_pred, zero_division=.0, average=average)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    metrics = {'f1': f1, 'accuracy': accuracy}\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvsEcmLgH09x"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    global CLASSIFICATION_THRESHOLD, PROBLEM_TYPE\n",
    "    preds = p.predictions\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    if PROBLEM_TYPE == \"multi_label_classification\":\n",
    "        result = multi_label_metrics(\n",
    "            predictions=preds,\n",
    "            labels=p.label_ids,\n",
    "            threshold=CLASSIFICATION_THRESHOLD\n",
    "        )\n",
    "    else:\n",
    "        result = single_label_metrics(\n",
    "            predictions=preds,\n",
    "            labels=p.label_ids,\n",
    "        )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3Pllvie3frB"
   },
   "source": [
    "### Chargement du mod√®le de base\n",
    "\n",
    "\n",
    "Maintenant que l'on a charg√© les donn√©es on connait le nombre d'√©tiquettes donc\n",
    "on peut charger le mod√®le et initialiser sa couche de classification.\n",
    "\n",
    "C'est ici que `PROBLEM_TYPE` entre en jeu:\n",
    "- `single_label_classification` : une seule √©tiquette par document\n",
    "- `multi_label_classification` : plusieurs √©tiquettes par document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyXlDL36aeC0"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "############    A Modifier    ###############\n",
    "#############################################\n",
    "\n",
    "SEED = 42  # Pour faciliter la reproductibilit√© des r√©sultats\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41qcQ0qu3frB"
   },
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# On initialise le g√©n√©rateur de nombres al√©atoires avant de charger le mod√®le\n",
    "# pour s'assurer que l'initialisation des poids de la couche de classification\n",
    "# soit toujours la m√™me.\n",
    "set_seed(SEED)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    BASE_MODEL_NAME, token=HF_TOKEN, num_labels=len(label_list),\n",
    "    problem_type=PROBLEM_TYPE,\n",
    "    # Pour avoir de belles etiquettes en sortie du mod√®le\n",
    "    id2label = {i: l for i, l in enumerate(label_list)},\n",
    "    label2id = {l: i for i, l in enumerate(label_list)},\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjW0J3_O3frA"
   },
   "source": [
    "### Pr√©paration de l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ym6smqsdgLV"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "############    A Modifier    ###############\n",
    "#############################################\n",
    "\n",
    "# Nom du mod√®le qui va √™tre entrain√©\n",
    "OUTPUT_MODEL_NAME = \"PARTAGES-encoder-v1-classif\"\n",
    "# Chemin o√π il va √™tre sauvegarder\n",
    "OUTPUT_DIR = os.path.join(os.environ['HOME'], \"PARTAGES\", OUTPUT_MODEL_NAME)\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAcRkemqAMiM"
   },
   "source": [
    "Le r√©sultat de l'entrainement sera stock√© dans:\n",
    "```\n",
    "~/PARTAGES/PARTAGES-encoder-v1-classif/\n",
    "- checkpoints/\n",
    "  - checkpoint-10\n",
    "  - checkpoint-20\n",
    "  - checkpoint-30\n",
    "  - checkpoint-...\n",
    "- training_args.json\n",
    "- model.pt\n",
    "- tokenizer.\n",
    "```\n",
    "\n",
    "Ainsi les points de contr√¥les (_checkpoints_) sont conserv√©s, et il sera possible de charger le meilleur mod√®le r√©sultant de l'entrainement en √©crivant:\n",
    "\n",
    "```python\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_path = os.path.join(os.environ['HOME'], \"PARTAGES\", \"PARTAGES-encoder-v1-classif\")\n",
    "# /!\\ Il est important d'utiliser AutoModelForTokenClassification et non\n",
    "# AutoModel (qui ne va pas charger la couche de classification)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Pour charger un checkpoint sp√©cifique\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path + \"/checkpoints/checkpoint-20\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wf0wzGySc3oV"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# Pour plus d'arguments\n",
    "# https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    os.path.join(OUTPUT_DIR, 'checkpoints'),\n",
    "    overwrite_output_dir=False,  # pour continuer l'entrainement\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2.0e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.01,\n",
    "    metric_for_best_model=\"f1_weighted\" if PROBLEM_TYPE == \"multi_label_classification\" else \"f1\",\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=True,\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_only_model=True,\n",
    "    save_total_limit=5,\n",
    "    report_to='tensorboard',\n",
    ")\n",
    "\n",
    "# Pour augmenter le batch_size mais ne pas avoir d'erreur de m√©moire il est possible\n",
    "#  d'utiliser le param√®tre `gradient_accumulation_steps` qui attend N batchs avant\n",
    "#  d'effectuer la r√©tropropagation. Par exemple `batch_size=64, gradient_accumulation_steps=1`\n",
    "#  est √©quivalent √† `batch_size=32, gradient_accumulation_steps=2` ou\n",
    "#  `batch_size=16, gradient_accumulation_steps=4`\n",
    "if os.path.exists(OUTPUT_DIR):\n",
    "    print(f\"\"\"Le dossier de sortie existe d√©j√† !\n",
    "L'entrainement va continuer s'il a √©t√© arr√™t√© ou ne rien faire si l'entrainement a termin√©.\n",
    "Chemin : {OUTPUT_DIR}\n",
    "Soyez s√ªr de ce qu'il se passe ou bien supprimez le dossier.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XlqJDzOkAwc"
   },
   "outputs": [],
   "source": [
    "# Exemple de document pass√© par le DataCollator (ajout de padding pour que tout\n",
    "#  les documents d'un m√™me lot (batch) aient la m√™me longueur\n",
    "sampled_batch = train_dataset.select_columns(['input_ids']).batch(8)[0]\n",
    "collated_batch = data_collator(sampled_batch)\n",
    "collated_doc = collated_batch['input_ids'][0]\n",
    "\n",
    "print(\"Exemple de document pass√© par le Data Collator (ce que le mod√®le va voir):\")\n",
    "doc_to_print = ' '.join(tokenizer.convert_ids_to_tokens(collated_doc)).replace('\\n', '\\\\n')\n",
    "print('\\n'.join(textwrap.wrap(doc_to_print, width=120, break_long_words=False, break_on_hyphens=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taQMbpzLajeM"
   },
   "outputs": [],
   "source": [
    "# Supprimer ou mettre √† `False` pour un entrainement r√©el\n",
    "debugging_mode = True\n",
    "if debugging_mode:\n",
    "    n_samples = min(len(train_dataset), len(eval_dataset))\n",
    "    n_samples = min(n_samples, 20)\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    print(\"!!!            Mode de debug         !!!\")\n",
    "    print(f\"!!!  Seuls {n_samples} examples sont utilis√©s  !!!\")\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    train_dataset = train_dataset.select(range(n_samples))\n",
    "    eval_dataset = eval_dataset.select(range(n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mG5IvgCc8BL"
   },
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    # Avec EarlyStopping, l'entrainement va s'arr√™ter apr√®s 3 epoch si\n",
    "    #  la f1_weighted (`metric_for_best_model`) ne s'am√©liore pas\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YqvkwlmthYis"
   },
   "outputs": [],
   "source": [
    "# Si erreur de taille v√©rifiez le param√®tre `problem_type` ou `num_labels` au chargement du mod√®le\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpYyuVLZ3frB"
   },
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BS-dR79WiwBm"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "trainer.save_model(os.path.join(OUTPUT_DIR))\n",
    "with open(os.path.join(OUTPUT_DIR, \"training_args.json\"), 'w') as f:\n",
    "  json.dump(json.loads(training_args.to_json_string()) | {'basemodel_name_or_path': model.name_or_path}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwZ8QmpL3frB"
   },
   "source": [
    "## Utilisation du mod√®le entrain√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3_G1Zjf3frB"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_path = os.path.join(os.environ['HOME'], \"PARTAGES\", OUTPUT_MODEL_NAME)\n",
    "# /!\\ Il est important d'utiliser AutoModelForTokenClassification et non\n",
    "# AutoModel (qui ne va pas charger la couche de classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcCZTrtw3frB"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "print(f\"Chargement du mod√®le {OUTPUT_MODEL_NAME}.\")\n",
    "pipe = pipeline(\"text-classification\", model=model_path, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0X4KHhV3frB"
   },
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    # Si un pr√©-traitement a √©t√© effectu√© pour cr√©er le corpus d'entrainement\n",
    "    #  il faut reproduire ce pr√©traitement ici.\n",
    "    return text.replace(\"c'est\", \"c' est\")\n",
    "\n",
    "texts = [\n",
    "    \"La patiente est enrhumm√©e, et a pris du parac√©tamol.\",\n",
    "    \"Une deuxi√®me phrase.\"\n",
    "]\n",
    "texts = [preprocessing(t) for t in texts]\n",
    "predictions = pipe(\n",
    "    texts,\n",
    "    batch_size=2,\n",
    "    top_k=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXI74vM43frB"
   },
   "outputs": [],
   "source": [
    "# Filtrage des √©tiquettes qui ont obtenu une probabilit√©e > a 0.7\n",
    "\n",
    "# Pour mieux choisir le seuil on peux par exemple:\n",
    "# - chercher le seuil qui maximise le f1 score sur le corpus de validation\n",
    "# - chercher un seuil par etiquette qui maximise le f1 score sur le corpus de validation\n",
    "\n",
    "# Note: l'etiquette sosy signifie \"Signes Ou SYmptomes\"\n",
    "for t, p in zip(texts, predictions):\n",
    "    chosen_labels = [l for l in p if l['score'] > 0.4]\n",
    "    print(f\"Le mod√®le a assign√© les √©tiquettes suivantes:\")\n",
    "    print(chosen_labels)\n",
    "    print(f\"au document: {t[:50]} [...]\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkecpPb5qV_L"
   },
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJeW-n9Y187x"
   },
   "source": [
    "Suivant le temps de calcul √† votre disposition et de la taille de vos jeux de donn√©es. Il est possible de chercher de meilleurs hyperparam√®tres automatiquement √† l'aide de la biblioth√®que `optuna`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F57oNfDXmWMU"
   },
   "outputs": [],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-GSda9QL2W2w"
   },
   "source": [
    "On choisit ici de chercher de meilleures valeurs pour la `learning_rate`, le `weight_decay` et une meilleure `seed` qui initialise les param√®tres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UjLoNhrypLLT"
   },
   "outputs": [],
   "source": [
    "from optuna import Trial\n",
    "\n",
    "def hp_space(trial: Trial) -> dict[str, float | int | str]:\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 2e-6, 2e-3, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.005, 0.1, log=True),\n",
    "        \"seed\": trial.suggest_int(\"seed\", 1, 40),\n",
    "    }\n",
    "\n",
    "# Utilisation d'une fonction model_init pour s'assurer de la reproducibilit√©\n",
    "def model_init():\n",
    "    global label_list, BASE_MODEL_NAME, HF_TOKEN, PROBLEM_TYPE\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        BASE_MODEL_NAME, token=HF_TOKEN, num_labels=len(label_list),\n",
    "        problem_type=PROBLEM_TYPE,\n",
    "        # Pour avoir de belles etiquettes en sortie du mod√®le\n",
    "        id2label = {i: l for i, l in enumerate(label_list)},\n",
    "        label2id = {l: i for i, l in enumerate(label_list)},\n",
    "    )\n",
    "\n",
    "# modification du trainer d√©j√† initialis√© avant pour bien r√©-initialiser le\n",
    "#  mod√®le √† chaque essai\n",
    "trainer.model_init = model_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RjrF4KlB3frC"
   },
   "outputs": [],
   "source": [
    "best_run = trainer.hyperparameter_search(direction=\"maximize\", hp_space=hp_space, n_trials=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smtIEhfM2tkG"
   },
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwiThxBM3frC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

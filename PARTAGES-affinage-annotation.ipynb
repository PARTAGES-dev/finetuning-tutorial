{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVrj8urZVCWa"
   },
   "source": [
    "# üè• Affinage (*fine-tuning*) de mod√®les encodeurs PARTAGES (BERT-like) pour  l'annotation (classification de tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmqlwwZw31V-"
   },
   "source": [
    "### Installation des libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVC4SALTcRzM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parfois il est plus simple d'installer torch via conda (ou d'utiliser le\n",
    "# paquet pytorch). S'il y a des erreurs avec numpy installez 'numpy<2'.\n",
    "\n",
    "# On utilise `datasets<4` car la version 4 de tokenizer ne permet plus de charger\n",
    "# des jeux de donn√©es √† l'aide de scripts de chargement. Certains jeux de\n",
    "# donn√©es utilisent toujours des scripts de chargements (notamment DrBenchmark).\n",
    "\n",
    "%pip install 'transformers[torch]' 'datasets<4' tensorboardX torch\n",
    "%pip install seqeval evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFwP77YO9Wuk"
   },
   "outputs": [],
   "source": [
    "# Petit hack pour √©viter un avertissement sp√©cifique √† Google Colab sur le\n",
    "# chargement du jeton huggingface\n",
    "try:\n",
    "  from huggingface_hub.utils import _auth\n",
    "  _auth._get_token_from_google_colab = lambda: None\n",
    "except ImportError:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnRO6drIDOo9"
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "###########    A Modifier    #########\n",
    "######################################\n",
    "\n",
    "# Si le jeu de donn√©e, mod√®le ou tokeniseur n'est pas public sur huggingface il\n",
    "# faut utiliser un jeton de connexion √† cr√©er ici : https://huggingface.co/settings/tokens\n",
    "\n",
    "# Pour l'instant les mod√®les PARTAGES sont priv√©s et accessibles avec le jeton\n",
    "#  communiqu√© avec ce fichier\n",
    "HF_TOKEN = \"\"\n",
    "\n",
    "# Ici on utilise un des mod√®les du projet PARTAGES\n",
    "# A modifier pour utiliser un autre mod√®le comme base d'affinage\n",
    "BASE_MODEL_NAME = \"WP4/PARTAGES-encoder-v1\"\n",
    "\n",
    "######################################\n",
    "assert HF_TOKEN != \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APx2gM0C5OsO"
   },
   "source": [
    "### Chargement du tokeniseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwWso1vocYuG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME, token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxJpOo-cdW_a"
   },
   "source": [
    "### Chargement et pr√©paration des donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D40ui_UX8R2G"
   },
   "source": [
    "Chargement des donn√©es au format ConLL-2003, la colonne 'tokens' est une liste qui repr√©sente chaque mot d'un document, la colonne 'ner_tags' est de la m√™me longueur que 'tokens' et indique l'√©tiquette de chaque mot.\n",
    "\n",
    "```python\n",
    "[{'id': str, 'tokens': list(str), 'ner_tags': list(int)}, ...]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2FZ7htyceiv"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, tokens_column, labels_column, label_all_tokens=False, max_length=None):\n",
    "    \"\"\"Retokenize each word to match current tokenizer and align new sub tokens with labels.\n",
    "    Adapted from from https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/token_classification.ipynb#scrollTo=n9qywopnIrJH\n",
    "\n",
    "    [(\"avec\", 0), (\"une\", 0), (\"tachycardie\", 1), (\"√†\", 0), (\"115\", 0)]\n",
    "\n",
    "    With label_all_tokens = False\n",
    "    [(\"avec\", 0), (\"une\", 0), (\"tac\", 1), (\"##hy\", -100), (\"##card\", -100), (\"##ie\", -100), (\"√†\", 0), (\"11\", 0), (\"##5\", -100)]\n",
    "\n",
    "    With label_all_tokens = True\n",
    "    [(\"avec\", 0), (\"une\", 0), (\"tac\", 1), (\"##hy\", 1), (\"##card\", 1), (\"##ie\", 1), (\"√†\", 0), (\"11\", 0), (\"##5\", 0)]\n",
    "    \"\"\"\n",
    "    if max_length is None:\n",
    "        max_length = tokenizer.model_max_length\n",
    "    tokenized_inputs = tokenizer(\n",
    "        list(examples[tokens_column]),\n",
    "        truncation=True, max_length=max_length,\n",
    "        padding='do_not_pad', is_split_into_words=True\n",
    "    )\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[labels_column]):\n",
    "        label_ids = []\n",
    "        previous_word_idx = None\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "###########    ZONE A Modifier POUR UTILISER    #########\n",
    "###########         VOS PROPRES DONNEES         #########\n",
    "##          ATTENTION AUX DONNEES PRIVEES NE PAS       ##\n",
    "##              EXECUTER SUR LE CLOUD                  ##\n",
    "#########################################################\n",
    "# En sortie de ces cellule:\n",
    "#  - label_list : liste des diff√©rentes √©tiquettes\n",
    "#  - train_dataset : un Dataset tokenis√© avec une colonne \"label\"\n",
    "#  - eval_dataset : un Dataset tokenis√© avec une colonne \"label\"\n",
    "\n",
    "# L'exemple est avec le corpus DEFT2021 que l'on peut obtenir via la collection\n",
    "#  de DrBenchmark (cf github.com/DrBenchmark/DrBenchmark)\n",
    "# https://aclanthology.org/2024.lrec-main.478.pdf\n",
    "# Chaque cas clinique est annot√© en extraction d'information au niveau token.\n",
    "#  Apr√®s extraction, le corps du texte est tokenis√© via la fonction\n",
    "#  preprocess_function.\n",
    "\n",
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset('DrBenchmark/DEFT2021', 'ner', trust_remote_code=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIWsbLfEciAo"
   },
   "outputs": [],
   "source": [
    "label_list = dataset['train'].features[f\"ner_tags\"].feature.names\n",
    "\n",
    "# Si les features du dataset ne sont pas d√©finies\n",
    "#label_list = list({l for d in dataset['train']['ner_tags'] for l in d})\n",
    "\n",
    "# Si la colonne des etiquettes contient des chaines de caract√®re il faut les transformer\n",
    "#  en entier\n",
    "\"\"\"id2label = {i: l for i, l in enumerate(label_list)}\n",
    "label2id = {l: i for i, l in enumerate(label_list)}\n",
    "dataset = dataset.map(lambda d: {'ner_tags': [label2id[l] for l in d['ner_tags']]})\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize dataset\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    fn_kwargs={\n",
    "        'tokens_column': 'tokens',\n",
    "        'labels_column': 'ner_tags',\n",
    "        'label_all_tokens': False,\n",
    "        # On met un maximum a 8192 pour √©viter les erreurs de m√©moire li√©s au\n",
    "        #  traitement de long documents mais c'est a modifier selon les besoins\n",
    "        #  et capacit√©s de calcul. Certains mod√®le n'ayant pas de limite.\n",
    "        'max_length': min(tokenizer.model_max_length, 8192),\n",
    "    },\n",
    "    batched=True, batch_size=100,\n",
    ")\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_dataset = tokenized_dataset[\"train\"]\n",
    "eval_dataset = tokenized_dataset[\"validation\"]\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xv6uBlJfGU0I"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import textwrap\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Affichage d'exemples au hasard\n",
    "to_show = [15, random.randint(0, len(train_dataset))]\n",
    "\n",
    "print(f\"Etiquettes : {label_list}\")\n",
    "idx_train_longest = int(np.argmax([len(e) for e in train_dataset['input_ids']]))\n",
    "print(f\"Plus long  doc train : idx {idx_train_longest:4d}, len {len(train_dataset[idx_train_longest]['input_ids']):4d}\")\n",
    "idx_train_shortest = int(np.argmin([len(e) for e in train_dataset['input_ids']]))\n",
    "print(f\"Plus court doc train : idx {idx_train_shortest:4d}, len {len(train_dataset[idx_train_shortest]['input_ids']):4d}\")\n",
    "\n",
    "idx_eval_longest = int(np.argmax([len(e) for e in eval_dataset['input_ids']]))\n",
    "print(f\"Plus long  doc valid : idx {idx_eval_longest:4d}, len {len(eval_dataset[idx_eval_longest]['input_ids']):4d}\")\n",
    "idx_eval_shortest = int(np.argmin([len(e) for e in eval_dataset['input_ids']]))\n",
    "print(f\"Plus court doc valid : idx {idx_eval_shortest:4d}, len {len(eval_dataset[idx_eval_shortest]['input_ids']):4d}\")\n",
    "\n",
    "for i in to_show:\n",
    "    doc = train_dataset[i]\n",
    "    print(f\"------ Document train {i} ------\")\n",
    "    print(f\"Nb. tokens: {len(doc['input_ids'])}\")\n",
    "    tokens = ' '.join(tokenizer.convert_ids_to_tokens(doc['input_ids'])).replace('\\n', '\\\\n')\n",
    "    print(f\"Tokens: {'\\n'.join(textwrap.wrap(tokens, width=120, break_long_words=False, break_on_hyphens=False))}\")\n",
    "    print(f\"Etiquettes: {doc['labels']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAQmfnuZdcMm"
   },
   "source": [
    "### D√©finition des m√©triques a rapporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mfo94xiCexPn"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import evaluate\n",
    "from seqeval.metrics import accuracy_score, classification_report\n",
    "\n",
    "class Seqeval(evaluate.Metric):\n",
    "    def _info(self):\n",
    "        return evaluate.MetricInfo(\n",
    "            description=\"\", citation=\"\",\n",
    "            homepage=\"https://github.com/chakki-works/seqeval\",\n",
    "            features=datasets.Features({\n",
    "                \"predictions\": datasets.Sequence(datasets.Value(\"string\", id=\"label\"), id=\"sequence\"),\n",
    "                 \"references\": datasets.Sequence(datasets.Value(\"string\", id=\"label\"), id=\"sequence\")\n",
    "            }))\n",
    "\n",
    "    def _compute(\n",
    "        self,\n",
    "        predictions,\n",
    "        references,\n",
    "        suffix: bool = False,\n",
    "        scheme: str | None = None,\n",
    "        mode: str | None = None,\n",
    "        sample_weight: list[int] | None = None,\n",
    "        zero_division: str | int = \"warn\",\n",
    "    ):\n",
    "        if scheme is not None:\n",
    "            try:\n",
    "                scheme_module = importlib.import_module(\"seqeval.scheme\")\n",
    "                scheme = getattr(scheme_module, scheme)\n",
    "            except AttributeError:\n",
    "                raise ValueError(f\"Scheme should be one of [IOB1, IOB2, IOE1, IOE2, IOBES, BILOU], got {scheme}\")\n",
    "        report = classification_report(\n",
    "            y_true=references,\n",
    "            y_pred=predictions,\n",
    "            suffix=suffix,\n",
    "            output_dict=True,\n",
    "            scheme=scheme,\n",
    "            mode=mode,\n",
    "            sample_weight=sample_weight,\n",
    "            zero_division=zero_division,\n",
    "        )\n",
    "        report.pop(\"macro avg\")\n",
    "        report.pop(\"weighted avg\")\n",
    "        overall_score = report.pop(\"micro avg\")\n",
    "\n",
    "        scores = {\n",
    "            type_name: {\n",
    "                \"precision\": score[\"precision\"],\n",
    "                \"recall\": score[\"recall\"],\n",
    "                \"f1\": score[\"f1-score\"],\n",
    "                \"number\": score[\"support\"],\n",
    "            }\n",
    "            for type_name, score in report.items()\n",
    "        }\n",
    "        scores[\"overall_precision\"] = overall_score[\"precision\"]\n",
    "        scores[\"overall_recall\"] = overall_score[\"recall\"]\n",
    "        scores[\"overall_f1\"] = overall_score[\"f1-score\"]\n",
    "        scores[\"overall_accuracy\"] = accuracy_score(y_true=references, y_pred=predictions)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0kTXS7cc-8J"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# On utilise la metrique SeqEval pour √©valuer l'annotation de tokens\n",
    "metric = Seqeval()\n",
    "\n",
    "def compute_metrics(p):\n",
    "    global metric\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels, zero_division=.0)\n",
    "\n",
    "    macro_values = [results[r][\"f1\"] for r in results if \"overall_\" not in r]\n",
    "    macro_f1 = sum(macro_values) / len(macro_values)\n",
    "\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"], \"macro_f1\": macro_f1,\n",
    "        \"accuracy\": results[\"overall_accuracy\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHirj93W3WrK"
   },
   "source": [
    "### Chargement du mod√®le de base\n",
    "\n",
    "\n",
    "Maintenant que l'on a charg√© les donn√©es on connait le nombre d'√©tiquettes donc\n",
    "on peut charger le mod√®le et initialiser sa couche de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yegvqc-ICqw"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "############    A Modifier    ###############\n",
    "#############################################\n",
    "\n",
    "SEED = 42  # Pour faciliter la reproductibilit√© des r√©sultats\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gK5NY6Gi3WrK"
   },
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "# On initialise le g√©n√©rateur de nombres al√©atoires avant de charger le mod√®le\n",
    "# pour s'assurer que l'initialisation des poids de la couche de classification\n",
    "# soient les m√™mes √† chaque fois.\n",
    "set_seed(SEED)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    BASE_MODEL_NAME, token=HF_TOKEN, num_labels=len(label_list),\n",
    "    # Pour avoir de belles etiquettes en sortie du mod√®le\n",
    "    id2label = {i: l for i, l in enumerate(label_list)},\n",
    "    label2id = {l: i for i, l in enumerate(label_list)},\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwB7XylV3WrJ"
   },
   "source": [
    "### Pr√©paration de l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ym6smqsdgLV"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "############    A Modifier    ###############\n",
    "#############################################\n",
    "\n",
    "OUTPUT_MODEL_NAME = \"PARTAGES-encoder-v1-annot\"\n",
    "OUTPUT_DIR = os.path.join(os.environ['HOME'], 'PARTAGES', OUTPUT_MODEL_NAME)\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAcRkemqAMiM"
   },
   "source": [
    "Le r√©sultat de l'entrainement sera stock√© dans:\n",
    "```\n",
    "~/PARTAGES/PARTAGES-encoder-v1-annot/\n",
    "- checkpoints/\n",
    "  - checkpoint-10\n",
    "  - checkpoint-20\n",
    "  - checkpoint-30\n",
    "  - checkpoint-...\n",
    "- training_args.json\n",
    "- model.pt\n",
    "- tokenizer.\n",
    "```\n",
    "\n",
    "Ainsi les points de contr√¥les sont conserv√©s, et il sera possible de charger le meilleur mod√®le r√©sultant de l'entrainement en √©crivant:\n",
    "\n",
    "```python\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "model_path = os.path.join(os.environ['HOME'], \"PARTAGES\", \"PARTAGES-encoder-v1-annot\")\n",
    "# /!\\ Il est important d'utiliser AutoModelForTokenClassification et non\n",
    "# AutoModel (qui ne va pas charger la couche de classification)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Pour charger un checkpoint sp√©cifique\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path + \"/checkpoints/checkpoint-20\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wf0wzGySc3oV"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "# Pour plus d'arguments\n",
    "# https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    os.path.join(OUTPUT_DIR, 'checkpoints'),\n",
    "    overwrite_output_dir=False,  # pour continuer l'entrainement\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2.0e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.01,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=True,\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_only_model=True,\n",
    "    save_total_limit=5,\n",
    "    seed=42,\n",
    "    report_to='tensorboard',\n",
    ")\n",
    "\n",
    "# Pour augmenter le batch_size mais ne pas avoir d'erreur de m√©moire il est possible\n",
    "#  d'utiliser le param√®tre `gradient_accumulation_steps` qui attend N batchs avant\n",
    "#  d'effectuer la r√©tropropagation. Par exemple `batch_size=64, gradient_accumulation_steps=1`\n",
    "#  est √©quivalent √† `batch_size=32, gradient_accumulation_steps=2` ou\n",
    "#  `batch_size=16, gradient_accumulation_steps=4`\n",
    "if os.path.exists(OUTPUT_DIR):\n",
    "    print(f\"\"\"Le dossier de sortie existe d√©j√† !\n",
    "L'entrainement va continuer s'il a √©t√© arr√™t√© ou ne rien faire si l'entrainement a termin√©.\n",
    "Chemin : {OUTPUT_DIR}\n",
    "Soyez s√ªr de ce qu'il se passe ou bien supprimez le dossier.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhA7V4ZUJibi"
   },
   "outputs": [],
   "source": [
    "# Exemple de document pass√© par le DataCollator (ajout de padding pour que tout\n",
    "#  les documents d'un m√™me lot (batch) aient la m√™me longueur\n",
    "sampled_batch = train_dataset.select_columns(['input_ids', 'attention_mask', 'labels']).select(range(8))\n",
    "collated_batch = data_collator(sampled_batch)\n",
    "collated_doc = collated_batch['input_ids'][0]\n",
    "\n",
    "print(\"Exemple de document pass√© par le Data Collator (ce que le mod√®le va voir):\")\n",
    "doc_to_print = ' '.join(tokenizer.convert_ids_to_tokens(collated_doc)).replace('\\n', '\\\\n')\n",
    "print('\\n'.join(textwrap.wrap(doc_to_print, width=120, break_long_words=False, break_on_hyphens=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZfIy9bfHN8Su"
   },
   "outputs": [],
   "source": [
    "# Supprimer ou mettre √† `False` pour un entrainement r√©el\n",
    "debugging_mode = True\n",
    "if debugging_mode:\n",
    "    n_samples = min(len(train_dataset), len(eval_dataset))\n",
    "    n_samples = min(n_samples, 20)\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    print(\"!!!            Mode de debug          !!!\")\n",
    "    print(f\"!!!  Seuls {n_samples} examples sont utilis√©s  !!!\")\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    train_dataset = train_dataset.select(range(n_samples))\n",
    "    eval_dataset = eval_dataset.select(range(n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mG5IvgCc8BL"
   },
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    # Avec EarlyStopping, l'entrainement va s'arr√™ter apr√®s 3 epoch si\n",
    "    #  la macro_f1 (`metric_for_best_model`) ne s'am√©liore pas\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YqvkwlmthYis"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJ3Lu1PI3WrK"
   },
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BS-dR79WiwBm"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "trainer.save_model(os.path.join(OUTPUT_DIR))\n",
    "with open(os.path.join(OUTPUT_DIR, \"training_args.json\"), 'w') as f:\n",
    "  json.dump(json.loads(training_args.to_json_string()) | {'basemodel_name_or_path': model.name_or_path}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5_eaTv43WrK"
   },
   "source": [
    "## Utilisation du mod√®le entrain√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AwNv10Ah3WrK"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "model_path = os.path.join(os.environ['HOME'], \"PARTAGES\", OUTPUT_MODEL_NAME)\n",
    "# /!\\ Il est important d'utiliser AutoModelForTokenClassification et non\n",
    "# AutoModel (qui ne va pas charger la couche de classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i49ydzcx3WrL"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "print(f\"Chargement du mod√®le {OUTPUT_MODEL_NAME}.\")\n",
    "pipe = pipeline(\"token-classification\", model=model_path, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foi3VGLM3WrL"
   },
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    # Si un pr√©-traitement a √©t√© effectu√© pour cr√©er le corpus d'entrainement\n",
    "    #  il faut reproduire ce pr√©traitement ici.\n",
    "    return text.replace(\"c'est\", \"c' est\")\n",
    "\n",
    "texts = [\n",
    "    \"La patiente est enrhumm√©e, et a pris du parac√©tamol.\",\n",
    "    \"Une deuxi√®me phrase.\"\n",
    "]\n",
    "texts = [preprocessing(t) for t in texts]\n",
    "\n",
    "# Pour le param√®tre `aggregation_strategy` voir https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.TokenClassificationPipeline.aggregation_strategy\n",
    "predictions = pipe(\n",
    "    texts,\n",
    "    batch_size=2,\n",
    "    # Utilise le premier sous-token de chaque mot comme √©tiquette\n",
    "    aggregation_strategy=\"first\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DP4fVzJSUpmN"
   },
   "outputs": [],
   "source": [
    "# Note: l'etiquette sosy signifie \"Signes Ou SYmptomes\"\n",
    "for t, p in zip(texts, predictions):\n",
    "    print(f\"Le mod√®le a identifi√© les entit√©s suivantes:\")\n",
    "    print(p)\n",
    "    print(f\"dans le document: {t[:50]} [...]\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkecpPb5qV_L"
   },
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJeW-n9Y187x"
   },
   "source": [
    "Suivant le temps de calcul √† votre disposition et de la taille de vos jeux de donn√©es. Il est possible de chercher de meilleurs hyperparam√®tres automatiquement √† l'aide de la biblioth√®que `optuna`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F57oNfDXmWMU"
   },
   "outputs": [],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-GSda9QL2W2w"
   },
   "source": [
    "On choisit ici de chercher de meilleures valeurs pour la `learning_rate`, le `weight_decay` et une meilleure `seed` qui initialise les param√®tres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UjLoNhrypLLT"
   },
   "outputs": [],
   "source": [
    "from optuna import Trial\n",
    "\n",
    "def hp_space(trial: Trial) -> dict[str, float | int | str]:\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 2e-6, 2e-3, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.005, 0.1, log=True),\n",
    "        \"seed\": trial.suggest_int(\"seed\", 1, 40),\n",
    "    }\n",
    "\n",
    "# Utilisation d'une fonction model_init pour s'assurer de la reproducibilit√©\n",
    "def model_init():\n",
    "    global label_list, base_model_name\n",
    "    return AutoModelForTokenClassification.from_pretrained(\n",
    "        base_model_name, token=HF_TOKEN, num_labels=len(label_list),\n",
    "        # Pour avoir de belles etiquettes en sortie du mod√®le\n",
    "        id2label = {i: l for i, l in enumerate(label_list)},\n",
    "        label2id = {l: i for i, l in enumerate(label_list)},\n",
    "    )\n",
    "\n",
    "# modification du trainer d√©j√† initialis√© avant pour bien r√©-initialiser le\n",
    "#  mod√®le √† chaque essai\n",
    "trainer.model_init = model_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfftMRgw3WrM"
   },
   "outputs": [],
   "source": [
    "best_run = trainer.hyperparameter_search(direction=\"maximize\", hp_space=hp_space, n_trials=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smtIEhfM2tkG"
   },
   "outputs": [],
   "source": [
    "best_run"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
